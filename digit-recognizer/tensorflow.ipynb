{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_onehot(a, classes=10):\n",
    "    m = a.shape[0]\n",
    "    b = np.zeros([m, classes])\n",
    "    b[np.arange(m), a.reshape(-1)] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('./data/input/train.csv')\n",
    "X_train = train_csv.iloc[:, 1:].values\n",
    "y_train_label = train_csv[['label']].values\n",
    "y_train = get_onehot(y_train_label)\n",
    "\n",
    "test_csv = pd.read_csv('./data/input/test.csv')\n",
    "X_test = train_csv.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqklEQVR4nGNgGCRgz/84BgYGBgYW\nLHL7rf/9x6Wv+sff5Vw45AK+/73Ai0NO9vzf17445Mwu/v0bgUMu9t/fd6sEscuJX/r3dz4OfQIX\n//77EIhDUvrv33+4HCpy7t+/Y+w4JFf8/XsEl5zI6b8/fHDIie35+zUWhxxD+t+/+3HJRX74e1gS\nhxz/nb9/A9AFmaC0vyIDAx8uyd//GP6q4rKS4dqteJxy9AQAbI49DkhoNMUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1105C0A90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgarr = X_train[0, :].reshape([28,28])\n",
    "Image.fromarray(imgarr.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_accuracy(y, y_hat):\n",
    "    is_right = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_hat, axis=1))\n",
    "    is_right = tf.cast(is_right, tf.float32)\n",
    "    accuracy = tf.reduce_mean(is_right)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = np.array([1,2,3,4,5,6,7,8])\n",
    "    b = np.array([1,3,2,4,5,7,6,8])\n",
    "    \n",
    "    y = tf.constant(get_onehot(a))\n",
    "    y_hat = tf.constant(get_onehot(b))\n",
    "    \n",
    "    accuracy = tf_accuracy(y, y_hat)\n",
    "    \n",
    "    res = sess.run(accuracy)\n",
    "    print(res)\n",
    "# ans: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistics regression\n",
    "def logistics_regression():\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "    \n",
    "    W = tf.get_variable('W', shape=[784, 10], initializer=tf.zeros_initializer())\n",
    "    b = tf.get_variable('b', shape=[1, 10], initializer=tf.zeros_initializer())\n",
    "    \n",
    "    z = tf.matmul(X, W) + b\n",
    "    y_hat = tf.nn.softmax(z)\n",
    "    \n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_hat), axis=1))\n",
    "#     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=z, labels=y))\n",
    "    accuracy = tf_accuracy(y, y_hat)\n",
    "    return X, y, cost, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.30259 0.4\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X, y, cost, accuracy = logistics_regression()\n",
    "    \n",
    "with tf.Session() as sess:    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    c, a = sess.run([cost, accuracy], feed_dict={X: X_train[:5, :], y: y_train[:5, :]})\n",
    "    print(c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple neural network\n",
    "def simple_neural_network(layers_dim=[200, 100]):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "    \n",
    "    A = X\n",
    "    hidden_layer_num = len(layers_dim)\n",
    "    layers_dim = [784] + layers_dim\n",
    "    for l in range(1, hidden_layer_num+1):\n",
    "        W = tf.get_variable('W'+str(l), shape=[layers_dim[l-1], layers_dim[l]],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable('b'+str(l), shape=[1, layers_dim[l]],\n",
    "                            initializer=tf.zeros_initializer())\n",
    "        Z = tf.matmul(A, W) + b\n",
    "        A = tf.nn.relu(Z)\n",
    "        \n",
    "    W = tf.get_variable('W_out', shape=[layers_dim[-1], 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable('b_out', shape=[1, 10], initializer=tf.zeros_initializer())\n",
    "    Z = tf.matmul(A, W) + b\n",
    "    y_hat = tf.nn.softmax(Z)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z, labels=y))\n",
    "    accuracy = tf_accuracy(y, y_hat)\n",
    "    \n",
    "    return X, y, cost, accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.6657 0.2\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X, y, cost, accuracy = simple_neural_network()\n",
    "    \n",
    "with tf.Session() as sess:    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    c, a = sess.run([cost, accuracy], feed_dict={X: X_train[:5, :], y: y_train[:5, :]})\n",
    "    print(c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, y, mini_batch_size):\n",
    "    m = X.shape[0]\n",
    "    batch_num = np.ceil(m / mini_batch_size).astype(int)\n",
    "    \n",
    "    minibatches = []\n",
    "    for i in range(batch_num):\n",
    "        lb = i * mini_batch_size\n",
    "        ub = (i+1) * mini_batch_size\n",
    "        \n",
    "        minibatches.append((X[lb:ub], y[lb:ub]))\n",
    "    \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (3, 1)\n",
      "(3, 3) (3, 1)\n",
      "(3, 3) (3, 1)\n",
      "(1, 3) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(10,3)\n",
    "y = np.random.randn(10,1)\n",
    "\n",
    "minibatches = random_mini_batches(X, y, 3)\n",
    "for mini_X, mini_y in minibatches:\n",
    "    print(mini_X.shape, mini_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, model_ele=logistics_regression(), mini_batch=64, epoch=10, learning_rate=0.001):\n",
    "    X_train = X_train / 255 # norm\n",
    "    \n",
    "    X, y, cost, accuracy = model_ele\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    m = X_train.shape[0]\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        for iepoch in range(epoch):\n",
    "            minibatches = random_mini_batches(X_train, y_train, mini_batch)\n",
    "            tot_cost = 0\n",
    "            tot_acc = 0\n",
    "            \n",
    "            for mini_X, mini_y in minibatches:\n",
    "                res_op, res_c, res_a = sess.run([optimizer, cost, accuracy], feed_dict={X: mini_X, y: mini_y})\n",
    "                \n",
    "                mini_m = mini_X.shape[0]\n",
    "                tot_cost += mini_m * res_c\n",
    "                tot_acc += mini_m * res_a\n",
    "                \n",
    "            print('epoch %i, cost=%f, accuracy=%f' % (iepoch, tot_cost/m, tot_acc/m))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>, <tf.Tensor 'Placeholder_1:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'Mean:0' shape=() dtype=float32>, <tf.Tensor 'Mean_1:0' shape=() dtype=float32>)\n",
      "epoch 0, cost=0.610534, accuracy=0.860048\n",
      "epoch 1, cost=0.341638, accuracy=0.906643\n",
      "epoch 2, cost=0.304788, accuracy=0.915000\n",
      "epoch 3, cost=0.287031, accuracy=0.919976\n",
      "epoch 4, cost=0.276027, accuracy=0.922429\n",
      "epoch 5, cost=0.268293, accuracy=0.924357\n",
      "epoch 6, cost=0.262429, accuracy=0.925595\n",
      "epoch 7, cost=0.257755, accuracy=0.926500\n",
      "epoch 8, cost=0.253896, accuracy=0.927905\n",
      "epoch 9, cost=0.250627, accuracy=0.928976\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_model(X_train, y_train, logistics_regression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, cost=0.235220, accuracy=0.928786\n",
      "epoch 1, cost=0.091272, accuracy=0.971905\n",
      "epoch 2, cost=0.053240, accuracy=0.983690\n",
      "epoch 3, cost=0.032356, accuracy=0.990238\n",
      "epoch 4, cost=0.028288, accuracy=0.990833\n",
      "epoch 5, cost=0.024626, accuracy=0.991500\n",
      "epoch 6, cost=0.022758, accuracy=0.991762\n",
      "epoch 7, cost=0.018976, accuracy=0.993429\n",
      "epoch 8, cost=0.014816, accuracy=0.995048\n",
      "epoch 9, cost=0.012124, accuracy=0.996000\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_model(X_train, y_train, simple_neural_network([500, 200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
