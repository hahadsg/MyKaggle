{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating all pair in (shop_id, item_id) for each date_block_num. And if row has not item_count from origin sales data, item_count will fill 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import display\n",
    "\n",
    "from mydatools.features_generate import features_read\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_col = 'ID'\n",
    "label_col = 'item_cnt_month'\n",
    "\n",
    "submission_path = './data/output/submission/lightgbm.csv'\n",
    "output_id_col = id_col\n",
    "output_label_col = label_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "full_df, feature_columns = features_read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valdation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = full_df['date_block_num'].copy()\n",
    "\n",
    "dates_trn = dates[dates <= 33]\n",
    "dates_tst = dates[dates == 34]\n",
    "\n",
    "trn_df = full_df[dates <= 33]\n",
    "tst_df = full_df[dates == 34]\n",
    "\n",
    "X_trn = trn_df[feature_columns]\n",
    "y_trn = trn_df[label_col]\n",
    "X_tst = tst_df[feature_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(metrics.mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lightgbm parameters tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX_trn = full_df[dates <= 32][feature_columns]\n",
    "yy_trn = full_df[dates <= 32][label_col]\n",
    "XX_val = full_df[dates == 33][feature_columns]\n",
    "yy_val = full_df[dates == 33][label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 1.13606\tvalid_1's rmse: 1.10224\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's rmse: 1.09583\tvalid_1's rmse: 1.07735\n",
      "[3]\ttraining's rmse: 1.05655\tvalid_1's rmse: 1.05479\n",
      "[4]\ttraining's rmse: 1.02382\tvalid_1's rmse: 1.02619\n",
      "[5]\ttraining's rmse: 0.995031\tvalid_1's rmse: 1.01123\n",
      "[6]\ttraining's rmse: 0.970421\tvalid_1's rmse: 0.999928\n",
      "[7]\ttraining's rmse: 0.949391\tvalid_1's rmse: 0.991009\n",
      "[8]\ttraining's rmse: 0.93481\tvalid_1's rmse: 0.98277\n",
      "[9]\ttraining's rmse: 0.919357\tvalid_1's rmse: 0.976922\n",
      "[10]\ttraining's rmse: 0.905905\tvalid_1's rmse: 0.973544\n",
      "[11]\ttraining's rmse: 0.89467\tvalid_1's rmse: 0.970501\n",
      "[12]\ttraining's rmse: 0.885167\tvalid_1's rmse: 0.968221\n",
      "[13]\ttraining's rmse: 0.876258\tvalid_1's rmse: 0.963248\n",
      "[14]\ttraining's rmse: 0.868661\tvalid_1's rmse: 0.9604\n",
      "[15]\ttraining's rmse: 0.862444\tvalid_1's rmse: 0.958847\n",
      "[16]\ttraining's rmse: 0.856462\tvalid_1's rmse: 0.955534\n",
      "[17]\ttraining's rmse: 0.851652\tvalid_1's rmse: 0.953287\n",
      "[18]\ttraining's rmse: 0.847593\tvalid_1's rmse: 0.952773\n",
      "[19]\ttraining's rmse: 0.842874\tvalid_1's rmse: 0.947733\n",
      "[20]\ttraining's rmse: 0.839175\tvalid_1's rmse: 0.943377\n",
      "[21]\ttraining's rmse: 0.835494\tvalid_1's rmse: 0.941151\n",
      "[22]\ttraining's rmse: 0.83272\tvalid_1's rmse: 0.939631\n",
      "[23]\ttraining's rmse: 0.829924\tvalid_1's rmse: 0.937083\n",
      "[24]\ttraining's rmse: 0.827884\tvalid_1's rmse: 0.937161\n",
      "[25]\ttraining's rmse: 0.825968\tvalid_1's rmse: 0.934381\n",
      "[26]\ttraining's rmse: 0.824405\tvalid_1's rmse: 0.93393\n",
      "[27]\ttraining's rmse: 0.822657\tvalid_1's rmse: 0.93322\n",
      "[28]\ttraining's rmse: 0.821241\tvalid_1's rmse: 0.928888\n",
      "[29]\ttraining's rmse: 0.820095\tvalid_1's rmse: 0.928997\n",
      "[30]\ttraining's rmse: 0.817965\tvalid_1's rmse: 0.92796\n",
      "[31]\ttraining's rmse: 0.816797\tvalid_1's rmse: 0.927923\n",
      "[32]\ttraining's rmse: 0.815065\tvalid_1's rmse: 0.926328\n",
      "[33]\ttraining's rmse: 0.814092\tvalid_1's rmse: 0.926431\n",
      "[34]\ttraining's rmse: 0.81228\tvalid_1's rmse: 0.921595\n",
      "[35]\ttraining's rmse: 0.81146\tvalid_1's rmse: 0.921171\n",
      "[36]\ttraining's rmse: 0.809709\tvalid_1's rmse: 0.916571\n",
      "[37]\ttraining's rmse: 0.808715\tvalid_1's rmse: 0.916465\n",
      "[38]\ttraining's rmse: 0.807013\tvalid_1's rmse: 0.914497\n",
      "[39]\ttraining's rmse: 0.805969\tvalid_1's rmse: 0.911486\n",
      "[40]\ttraining's rmse: 0.804751\tvalid_1's rmse: 0.910483\n",
      "[41]\ttraining's rmse: 0.803378\tvalid_1's rmse: 0.908716\n",
      "[42]\ttraining's rmse: 0.802115\tvalid_1's rmse: 0.907213\n",
      "[43]\ttraining's rmse: 0.801389\tvalid_1's rmse: 0.906862\n",
      "[44]\ttraining's rmse: 0.80055\tvalid_1's rmse: 0.906366\n",
      "[45]\ttraining's rmse: 0.799202\tvalid_1's rmse: 0.906309\n",
      "[46]\ttraining's rmse: 0.798637\tvalid_1's rmse: 0.906133\n",
      "[47]\ttraining's rmse: 0.7978\tvalid_1's rmse: 0.905535\n",
      "[48]\ttraining's rmse: 0.797052\tvalid_1's rmse: 0.904611\n",
      "[49]\ttraining's rmse: 0.796368\tvalid_1's rmse: 0.904596\n",
      "[50]\ttraining's rmse: 0.795312\tvalid_1's rmse: 0.90288\n",
      "[51]\ttraining's rmse: 0.794567\tvalid_1's rmse: 0.902681\n",
      "[52]\ttraining's rmse: 0.793151\tvalid_1's rmse: 0.901983\n",
      "[53]\ttraining's rmse: 0.792033\tvalid_1's rmse: 0.901848\n",
      "[54]\ttraining's rmse: 0.791388\tvalid_1's rmse: 0.90144\n",
      "[55]\ttraining's rmse: 0.79071\tvalid_1's rmse: 0.901403\n",
      "[56]\ttraining's rmse: 0.790287\tvalid_1's rmse: 0.90111\n",
      "[57]\ttraining's rmse: 0.789377\tvalid_1's rmse: 0.900332\n",
      "[58]\ttraining's rmse: 0.788893\tvalid_1's rmse: 0.900235\n",
      "[59]\ttraining's rmse: 0.788351\tvalid_1's rmse: 0.900051\n",
      "[60]\ttraining's rmse: 0.788111\tvalid_1's rmse: 0.899821\n",
      "[61]\ttraining's rmse: 0.787464\tvalid_1's rmse: 0.899583\n",
      "[62]\ttraining's rmse: 0.787067\tvalid_1's rmse: 0.89931\n",
      "[63]\ttraining's rmse: 0.786826\tvalid_1's rmse: 0.899108\n",
      "[64]\ttraining's rmse: 0.786237\tvalid_1's rmse: 0.898889\n",
      "[65]\ttraining's rmse: 0.785764\tvalid_1's rmse: 0.898479\n",
      "[66]\ttraining's rmse: 0.785361\tvalid_1's rmse: 0.899273\n",
      "[67]\ttraining's rmse: 0.784891\tvalid_1's rmse: 0.898697\n",
      "[68]\ttraining's rmse: 0.784503\tvalid_1's rmse: 0.898993\n",
      "[69]\ttraining's rmse: 0.784073\tvalid_1's rmse: 0.89909\n",
      "[70]\ttraining's rmse: 0.783661\tvalid_1's rmse: 0.898527\n",
      "[71]\ttraining's rmse: 0.783246\tvalid_1's rmse: 0.898874\n",
      "[72]\ttraining's rmse: 0.782845\tvalid_1's rmse: 0.899003\n",
      "[73]\ttraining's rmse: 0.782343\tvalid_1's rmse: 0.899451\n",
      "[74]\ttraining's rmse: 0.781824\tvalid_1's rmse: 0.899495\n",
      "[75]\ttraining's rmse: 0.781464\tvalid_1's rmse: 0.899088\n",
      "[76]\ttraining's rmse: 0.781188\tvalid_1's rmse: 0.89898\n",
      "[77]\ttraining's rmse: 0.780788\tvalid_1's rmse: 0.89907\n",
      "[78]\ttraining's rmse: 0.78042\tvalid_1's rmse: 0.8989\n",
      "[79]\ttraining's rmse: 0.779655\tvalid_1's rmse: 0.898883\n",
      "[80]\ttraining's rmse: 0.779447\tvalid_1's rmse: 0.898877\n",
      "[81]\ttraining's rmse: 0.779054\tvalid_1's rmse: 0.89874\n",
      "[82]\ttraining's rmse: 0.778661\tvalid_1's rmse: 0.898561\n",
      "[83]\ttraining's rmse: 0.77782\tvalid_1's rmse: 0.897413\n",
      "[84]\ttraining's rmse: 0.777287\tvalid_1's rmse: 0.893852\n",
      "[85]\ttraining's rmse: 0.776907\tvalid_1's rmse: 0.893556\n",
      "[86]\ttraining's rmse: 0.776576\tvalid_1's rmse: 0.893545\n",
      "[87]\ttraining's rmse: 0.7763\tvalid_1's rmse: 0.893324\n",
      "[88]\ttraining's rmse: 0.775957\tvalid_1's rmse: 0.893433\n",
      "[89]\ttraining's rmse: 0.775256\tvalid_1's rmse: 0.893471\n",
      "[90]\ttraining's rmse: 0.775003\tvalid_1's rmse: 0.893482\n",
      "[91]\ttraining's rmse: 0.774758\tvalid_1's rmse: 0.893239\n",
      "[92]\ttraining's rmse: 0.774079\tvalid_1's rmse: 0.892596\n",
      "[93]\ttraining's rmse: 0.773776\tvalid_1's rmse: 0.892606\n",
      "[94]\ttraining's rmse: 0.773475\tvalid_1's rmse: 0.892131\n",
      "[95]\ttraining's rmse: 0.77312\tvalid_1's rmse: 0.891741\n",
      "[96]\ttraining's rmse: 0.7728\tvalid_1's rmse: 0.891935\n",
      "[97]\ttraining's rmse: 0.772577\tvalid_1's rmse: 0.891954\n",
      "[98]\ttraining's rmse: 0.772273\tvalid_1's rmse: 0.891698\n",
      "[99]\ttraining's rmse: 0.772004\tvalid_1's rmse: 0.89102\n",
      "[100]\ttraining's rmse: 0.771786\tvalid_1's rmse: 0.890994\n",
      "[101]\ttraining's rmse: 0.771589\tvalid_1's rmse: 0.890789\n",
      "[102]\ttraining's rmse: 0.771379\tvalid_1's rmse: 0.89065\n",
      "[103]\ttraining's rmse: 0.77109\tvalid_1's rmse: 0.89068\n",
      "[104]\ttraining's rmse: 0.770977\tvalid_1's rmse: 0.890661\n",
      "[105]\ttraining's rmse: 0.770431\tvalid_1's rmse: 0.889697\n",
      "[106]\ttraining's rmse: 0.770203\tvalid_1's rmse: 0.889771\n",
      "[107]\ttraining's rmse: 0.769997\tvalid_1's rmse: 0.88974\n",
      "[108]\ttraining's rmse: 0.769748\tvalid_1's rmse: 0.889384\n",
      "[109]\ttraining's rmse: 0.769544\tvalid_1's rmse: 0.889434\n",
      "[110]\ttraining's rmse: 0.769259\tvalid_1's rmse: 0.888812\n",
      "[111]\ttraining's rmse: 0.769068\tvalid_1's rmse: 0.888742\n",
      "[112]\ttraining's rmse: 0.768779\tvalid_1's rmse: 0.888773\n",
      "[113]\ttraining's rmse: 0.768454\tvalid_1's rmse: 0.888791\n",
      "[114]\ttraining's rmse: 0.768202\tvalid_1's rmse: 0.888403\n",
      "[115]\ttraining's rmse: 0.767959\tvalid_1's rmse: 0.8883\n",
      "[116]\ttraining's rmse: 0.767593\tvalid_1's rmse: 0.887926\n",
      "[117]\ttraining's rmse: 0.767426\tvalid_1's rmse: 0.887878\n",
      "[118]\ttraining's rmse: 0.767021\tvalid_1's rmse: 0.887925\n",
      "[119]\ttraining's rmse: 0.766729\tvalid_1's rmse: 0.887903\n",
      "[120]\ttraining's rmse: 0.766471\tvalid_1's rmse: 0.887575\n",
      "[121]\ttraining's rmse: 0.766035\tvalid_1's rmse: 0.887571\n",
      "[122]\ttraining's rmse: 0.765929\tvalid_1's rmse: 0.887516\n",
      "[123]\ttraining's rmse: 0.765766\tvalid_1's rmse: 0.887437\n",
      "[124]\ttraining's rmse: 0.765256\tvalid_1's rmse: 0.887192\n",
      "[125]\ttraining's rmse: 0.765034\tvalid_1's rmse: 0.88728\n",
      "[126]\ttraining's rmse: 0.764765\tvalid_1's rmse: 0.886908\n",
      "[127]\ttraining's rmse: 0.764579\tvalid_1's rmse: 0.886954\n",
      "[128]\ttraining's rmse: 0.764444\tvalid_1's rmse: 0.886812\n",
      "[129]\ttraining's rmse: 0.764305\tvalid_1's rmse: 0.886883\n",
      "[130]\ttraining's rmse: 0.764134\tvalid_1's rmse: 0.886867\n",
      "[131]\ttraining's rmse: 0.763422\tvalid_1's rmse: 0.887173\n",
      "[132]\ttraining's rmse: 0.763026\tvalid_1's rmse: 0.88684\n",
      "[133]\ttraining's rmse: 0.762794\tvalid_1's rmse: 0.886713\n",
      "[134]\ttraining's rmse: 0.762669\tvalid_1's rmse: 0.886737\n",
      "[135]\ttraining's rmse: 0.762261\tvalid_1's rmse: 0.886939\n",
      "[136]\ttraining's rmse: 0.762124\tvalid_1's rmse: 0.886843\n",
      "[137]\ttraining's rmse: 0.761571\tvalid_1's rmse: 0.886679\n",
      "[138]\ttraining's rmse: 0.761421\tvalid_1's rmse: 0.886403\n",
      "[139]\ttraining's rmse: 0.761264\tvalid_1's rmse: 0.886386\n",
      "[140]\ttraining's rmse: 0.761099\tvalid_1's rmse: 0.886599\n",
      "[141]\ttraining's rmse: 0.760726\tvalid_1's rmse: 0.886625\n",
      "[142]\ttraining's rmse: 0.760303\tvalid_1's rmse: 0.886016\n",
      "[143]\ttraining's rmse: 0.760108\tvalid_1's rmse: 0.885964\n",
      "[144]\ttraining's rmse: 0.760003\tvalid_1's rmse: 0.885965\n",
      "[145]\ttraining's rmse: 0.759905\tvalid_1's rmse: 0.885966\n",
      "[146]\ttraining's rmse: 0.759736\tvalid_1's rmse: 0.885756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147]\ttraining's rmse: 0.759224\tvalid_1's rmse: 0.885652\n",
      "[148]\ttraining's rmse: 0.759014\tvalid_1's rmse: 0.885587\n",
      "[149]\ttraining's rmse: 0.75872\tvalid_1's rmse: 0.885298\n",
      "[150]\ttraining's rmse: 0.758563\tvalid_1's rmse: 0.885263\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[150]\ttraining's rmse: 0.758563\tvalid_1's rmse: 0.885263\n"
     ]
    }
   ],
   "source": [
    "trn_lgb = lgb.Dataset(XX_trn, yy_trn)\n",
    "val_lgb = lgb.Dataset(XX_val, yy_val)\n",
    "\n",
    "lgb_params = {\n",
    "    'application': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 1,\n",
    "    'seed': 0,\n",
    "}\n",
    "train_round = 150\n",
    "\n",
    "bst = lgb.train(lgb_params, trn_lgb, train_round, valid_sets=[trn_lgb, val_lgb], early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**trian use all data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.train(lgb_params, lgb.Dataset(X_trn, y_trn), train_round)\n",
    "predictions = lgb_model.predict(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(predictions.clip(0,20), columns=[output_label_col])\n",
    "res_df[output_id_col] = tst_df[output_id_col].astype(int).values\n",
    "res_df.sort_values('ID')[[output_id_col, output_label_col]].to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
