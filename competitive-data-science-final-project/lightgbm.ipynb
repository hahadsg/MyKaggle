{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating all pair in (shop_id, item_id) for each date_block_num. And if row has not item_count from origin sales data, item_count will fill 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import display\n",
    "\n",
    "from mydatools.features_generate import features_read\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_col = 'ID'\n",
    "label_col = 'item_cnt_month'\n",
    "\n",
    "submission_path = './data/output/submission/lightgbm.csv'\n",
    "output_id_col = id_col\n",
    "output_label_col = label_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "full_df, feature_columns = features_read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valdation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = full_df['date_block_num'].copy()\n",
    "\n",
    "dates_trn = dates[dates <= 33]\n",
    "dates_tst = dates[dates == 34]\n",
    "\n",
    "trn_df = full_df[dates <= 33]\n",
    "tst_df = full_df[dates == 34]\n",
    "\n",
    "X_trn = trn_df[feature_columns]\n",
    "y_trn = trn_df[label_col]\n",
    "X_tst = tst_df[feature_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(metrics.mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lightgbm parameters tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX_trn = full_df[dates <= 32][feature_columns]\n",
    "yy_trn = full_df[dates <= 32][label_col]\n",
    "XX_val = full_df[dates == 33][feature_columns]\n",
    "yy_val = full_df[dates == 33][label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 1.13974\tvalid_1's rmse: 1.10691\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's rmse: 1.09969\tvalid_1's rmse: 1.08105\n",
      "[3]\ttraining's rmse: 1.06622\tvalid_1's rmse: 1.052\n",
      "[4]\ttraining's rmse: 1.03792\tvalid_1's rmse: 1.02607\n",
      "[5]\ttraining's rmse: 1.00609\tvalid_1's rmse: 1.0081\n",
      "[6]\ttraining's rmse: 0.983047\tvalid_1's rmse: 0.996264\n",
      "[7]\ttraining's rmse: 0.958717\tvalid_1's rmse: 0.984539\n",
      "[8]\ttraining's rmse: 0.940494\tvalid_1's rmse: 0.978195\n",
      "[9]\ttraining's rmse: 0.923412\tvalid_1's rmse: 0.97096\n",
      "[10]\ttraining's rmse: 0.908627\tvalid_1's rmse: 0.96556\n",
      "[11]\ttraining's rmse: 0.895897\tvalid_1's rmse: 0.960899\n",
      "[12]\ttraining's rmse: 0.885635\tvalid_1's rmse: 0.957885\n",
      "[13]\ttraining's rmse: 0.877481\tvalid_1's rmse: 0.956268\n",
      "[14]\ttraining's rmse: 0.870309\tvalid_1's rmse: 0.953756\n",
      "[15]\ttraining's rmse: 0.863621\tvalid_1's rmse: 0.948511\n",
      "[16]\ttraining's rmse: 0.857585\tvalid_1's rmse: 0.943964\n",
      "[17]\ttraining's rmse: 0.85216\tvalid_1's rmse: 0.940886\n",
      "[18]\ttraining's rmse: 0.847363\tvalid_1's rmse: 0.940759\n",
      "[19]\ttraining's rmse: 0.843153\tvalid_1's rmse: 0.93655\n",
      "[20]\ttraining's rmse: 0.839348\tvalid_1's rmse: 0.936089\n",
      "[21]\ttraining's rmse: 0.83628\tvalid_1's rmse: 0.933524\n",
      "[22]\ttraining's rmse: 0.833389\tvalid_1's rmse: 0.932182\n",
      "[23]\ttraining's rmse: 0.830867\tvalid_1's rmse: 0.93102\n",
      "[24]\ttraining's rmse: 0.828629\tvalid_1's rmse: 0.930598\n",
      "[25]\ttraining's rmse: 0.826597\tvalid_1's rmse: 0.930365\n",
      "[26]\ttraining's rmse: 0.824856\tvalid_1's rmse: 0.929056\n",
      "[27]\ttraining's rmse: 0.822906\tvalid_1's rmse: 0.927651\n",
      "[28]\ttraining's rmse: 0.821675\tvalid_1's rmse: 0.927392\n",
      "[29]\ttraining's rmse: 0.819993\tvalid_1's rmse: 0.923135\n",
      "[30]\ttraining's rmse: 0.818553\tvalid_1's rmse: 0.922565\n",
      "[31]\ttraining's rmse: 0.817087\tvalid_1's rmse: 0.920944\n",
      "[32]\ttraining's rmse: 0.816248\tvalid_1's rmse: 0.920748\n",
      "[33]\ttraining's rmse: 0.815\tvalid_1's rmse: 0.919851\n",
      "[34]\ttraining's rmse: 0.814035\tvalid_1's rmse: 0.919468\n",
      "[35]\ttraining's rmse: 0.813102\tvalid_1's rmse: 0.918926\n",
      "[36]\ttraining's rmse: 0.811964\tvalid_1's rmse: 0.917632\n",
      "[37]\ttraining's rmse: 0.810477\tvalid_1's rmse: 0.917729\n",
      "[38]\ttraining's rmse: 0.80956\tvalid_1's rmse: 0.916747\n",
      "[39]\ttraining's rmse: 0.807378\tvalid_1's rmse: 0.915751\n",
      "[40]\ttraining's rmse: 0.806419\tvalid_1's rmse: 0.915732\n",
      "[41]\ttraining's rmse: 0.804881\tvalid_1's rmse: 0.914615\n",
      "[42]\ttraining's rmse: 0.803263\tvalid_1's rmse: 0.914257\n",
      "[43]\ttraining's rmse: 0.802426\tvalid_1's rmse: 0.91363\n",
      "[44]\ttraining's rmse: 0.80188\tvalid_1's rmse: 0.913607\n",
      "[45]\ttraining's rmse: 0.80035\tvalid_1's rmse: 0.912495\n",
      "[46]\ttraining's rmse: 0.799287\tvalid_1's rmse: 0.91185\n",
      "[47]\ttraining's rmse: 0.798678\tvalid_1's rmse: 0.911151\n",
      "[48]\ttraining's rmse: 0.797932\tvalid_1's rmse: 0.910986\n",
      "[49]\ttraining's rmse: 0.797465\tvalid_1's rmse: 0.910579\n",
      "[50]\ttraining's rmse: 0.796443\tvalid_1's rmse: 0.907395\n",
      "[51]\ttraining's rmse: 0.795858\tvalid_1's rmse: 0.907016\n",
      "[52]\ttraining's rmse: 0.79505\tvalid_1's rmse: 0.905703\n",
      "[53]\ttraining's rmse: 0.794827\tvalid_1's rmse: 0.905708\n",
      "[54]\ttraining's rmse: 0.794441\tvalid_1's rmse: 0.905317\n",
      "[55]\ttraining's rmse: 0.793662\tvalid_1's rmse: 0.906127\n",
      "[56]\ttraining's rmse: 0.793094\tvalid_1's rmse: 0.906146\n",
      "[57]\ttraining's rmse: 0.792672\tvalid_1's rmse: 0.905985\n",
      "[58]\ttraining's rmse: 0.791797\tvalid_1's rmse: 0.906157\n",
      "[59]\ttraining's rmse: 0.790843\tvalid_1's rmse: 0.905488\n",
      "[60]\ttraining's rmse: 0.790396\tvalid_1's rmse: 0.904852\n",
      "[61]\ttraining's rmse: 0.790018\tvalid_1's rmse: 0.904649\n",
      "[62]\ttraining's rmse: 0.789756\tvalid_1's rmse: 0.904419\n",
      "[63]\ttraining's rmse: 0.789449\tvalid_1's rmse: 0.90388\n",
      "[64]\ttraining's rmse: 0.788169\tvalid_1's rmse: 0.903336\n",
      "[65]\ttraining's rmse: 0.787911\tvalid_1's rmse: 0.903013\n",
      "[66]\ttraining's rmse: 0.787622\tvalid_1's rmse: 0.902812\n",
      "[67]\ttraining's rmse: 0.786879\tvalid_1's rmse: 0.901788\n",
      "[68]\ttraining's rmse: 0.786493\tvalid_1's rmse: 0.901896\n",
      "[69]\ttraining's rmse: 0.786123\tvalid_1's rmse: 0.901797\n",
      "[70]\ttraining's rmse: 0.785734\tvalid_1's rmse: 0.901577\n",
      "[71]\ttraining's rmse: 0.785439\tvalid_1's rmse: 0.901936\n",
      "[72]\ttraining's rmse: 0.784973\tvalid_1's rmse: 0.901151\n",
      "[73]\ttraining's rmse: 0.78369\tvalid_1's rmse: 0.897727\n",
      "[74]\ttraining's rmse: 0.783303\tvalid_1's rmse: 0.896925\n",
      "[75]\ttraining's rmse: 0.782401\tvalid_1's rmse: 0.895978\n",
      "[76]\ttraining's rmse: 0.781971\tvalid_1's rmse: 0.89584\n",
      "[77]\ttraining's rmse: 0.781535\tvalid_1's rmse: 0.896119\n",
      "[78]\ttraining's rmse: 0.781268\tvalid_1's rmse: 0.896068\n",
      "[79]\ttraining's rmse: 0.781084\tvalid_1's rmse: 0.896044\n",
      "[80]\ttraining's rmse: 0.780695\tvalid_1's rmse: 0.896259\n",
      "[81]\ttraining's rmse: 0.780496\tvalid_1's rmse: 0.896304\n",
      "[82]\ttraining's rmse: 0.78017\tvalid_1's rmse: 0.895995\n",
      "[83]\ttraining's rmse: 0.779838\tvalid_1's rmse: 0.895767\n",
      "[84]\ttraining's rmse: 0.779459\tvalid_1's rmse: 0.895701\n",
      "[85]\ttraining's rmse: 0.779284\tvalid_1's rmse: 0.895647\n",
      "[86]\ttraining's rmse: 0.778928\tvalid_1's rmse: 0.895101\n",
      "[87]\ttraining's rmse: 0.778589\tvalid_1's rmse: 0.895004\n",
      "[88]\ttraining's rmse: 0.778115\tvalid_1's rmse: 0.895047\n",
      "[89]\ttraining's rmse: 0.7775\tvalid_1's rmse: 0.894917\n",
      "[90]\ttraining's rmse: 0.776834\tvalid_1's rmse: 0.89335\n",
      "[91]\ttraining's rmse: 0.776403\tvalid_1's rmse: 0.892449\n",
      "[92]\ttraining's rmse: 0.776031\tvalid_1's rmse: 0.89199\n",
      "[93]\ttraining's rmse: 0.775621\tvalid_1's rmse: 0.89175\n",
      "[94]\ttraining's rmse: 0.77547\tvalid_1's rmse: 0.891634\n",
      "[95]\ttraining's rmse: 0.775129\tvalid_1's rmse: 0.89153\n",
      "[96]\ttraining's rmse: 0.774761\tvalid_1's rmse: 0.891555\n",
      "[97]\ttraining's rmse: 0.774423\tvalid_1's rmse: 0.891883\n",
      "[98]\ttraining's rmse: 0.774246\tvalid_1's rmse: 0.891747\n",
      "[99]\ttraining's rmse: 0.774096\tvalid_1's rmse: 0.891653\n",
      "[100]\ttraining's rmse: 0.773835\tvalid_1's rmse: 0.891479\n",
      "[101]\ttraining's rmse: 0.773261\tvalid_1's rmse: 0.89046\n",
      "[102]\ttraining's rmse: 0.772853\tvalid_1's rmse: 0.890251\n",
      "[103]\ttraining's rmse: 0.77256\tvalid_1's rmse: 0.890272\n",
      "[104]\ttraining's rmse: 0.772328\tvalid_1's rmse: 0.890207\n",
      "[105]\ttraining's rmse: 0.772091\tvalid_1's rmse: 0.890168\n",
      "[106]\ttraining's rmse: 0.771828\tvalid_1's rmse: 0.890617\n",
      "[107]\ttraining's rmse: 0.771635\tvalid_1's rmse: 0.890412\n",
      "[108]\ttraining's rmse: 0.771058\tvalid_1's rmse: 0.889466\n",
      "[109]\ttraining's rmse: 0.770326\tvalid_1's rmse: 0.888452\n",
      "[110]\ttraining's rmse: 0.769678\tvalid_1's rmse: 0.887687\n",
      "[111]\ttraining's rmse: 0.769534\tvalid_1's rmse: 0.887594\n",
      "[112]\ttraining's rmse: 0.769393\tvalid_1's rmse: 0.887606\n",
      "[113]\ttraining's rmse: 0.768672\tvalid_1's rmse: 0.887961\n",
      "[114]\ttraining's rmse: 0.768501\tvalid_1's rmse: 0.887879\n",
      "[115]\ttraining's rmse: 0.768233\tvalid_1's rmse: 0.887679\n",
      "[116]\ttraining's rmse: 0.767869\tvalid_1's rmse: 0.88725\n",
      "[117]\ttraining's rmse: 0.76777\tvalid_1's rmse: 0.887159\n",
      "[118]\ttraining's rmse: 0.767539\tvalid_1's rmse: 0.8869\n",
      "[119]\ttraining's rmse: 0.767329\tvalid_1's rmse: 0.886871\n",
      "[120]\ttraining's rmse: 0.76716\tvalid_1's rmse: 0.886987\n",
      "[121]\ttraining's rmse: 0.767015\tvalid_1's rmse: 0.886846\n",
      "[122]\ttraining's rmse: 0.766883\tvalid_1's rmse: 0.88682\n",
      "[123]\ttraining's rmse: 0.766649\tvalid_1's rmse: 0.886561\n",
      "[124]\ttraining's rmse: 0.766446\tvalid_1's rmse: 0.886205\n",
      "[125]\ttraining's rmse: 0.765711\tvalid_1's rmse: 0.886007\n",
      "[126]\ttraining's rmse: 0.765527\tvalid_1's rmse: 0.885867\n",
      "[127]\ttraining's rmse: 0.764891\tvalid_1's rmse: 0.885788\n",
      "[128]\ttraining's rmse: 0.764676\tvalid_1's rmse: 0.885719\n",
      "[129]\ttraining's rmse: 0.764558\tvalid_1's rmse: 0.885762\n",
      "[130]\ttraining's rmse: 0.764207\tvalid_1's rmse: 0.885406\n",
      "[131]\ttraining's rmse: 0.763926\tvalid_1's rmse: 0.885128\n",
      "[132]\ttraining's rmse: 0.763762\tvalid_1's rmse: 0.885126\n",
      "[133]\ttraining's rmse: 0.76354\tvalid_1's rmse: 0.884793\n",
      "[134]\ttraining's rmse: 0.763407\tvalid_1's rmse: 0.884676\n",
      "[135]\ttraining's rmse: 0.762887\tvalid_1's rmse: 0.884117\n",
      "[136]\ttraining's rmse: 0.762821\tvalid_1's rmse: 0.884108\n",
      "[137]\ttraining's rmse: 0.762218\tvalid_1's rmse: 0.883534\n",
      "[138]\ttraining's rmse: 0.762098\tvalid_1's rmse: 0.883531\n",
      "[139]\ttraining's rmse: 0.762017\tvalid_1's rmse: 0.883467\n",
      "[140]\ttraining's rmse: 0.761825\tvalid_1's rmse: 0.883333\n",
      "[141]\ttraining's rmse: 0.761691\tvalid_1's rmse: 0.883412\n",
      "[142]\ttraining's rmse: 0.761459\tvalid_1's rmse: 0.882902\n",
      "[143]\ttraining's rmse: 0.761265\tvalid_1's rmse: 0.882957\n",
      "[144]\ttraining's rmse: 0.760874\tvalid_1's rmse: 0.882797\n",
      "[145]\ttraining's rmse: 0.760705\tvalid_1's rmse: 0.882653\n",
      "[146]\ttraining's rmse: 0.760484\tvalid_1's rmse: 0.882472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147]\ttraining's rmse: 0.760378\tvalid_1's rmse: 0.882362\n",
      "[148]\ttraining's rmse: 0.760221\tvalid_1's rmse: 0.882432\n",
      "[149]\ttraining's rmse: 0.760136\tvalid_1's rmse: 0.882446\n",
      "[150]\ttraining's rmse: 0.760025\tvalid_1's rmse: 0.882416\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[150]\ttraining's rmse: 0.760025\tvalid_1's rmse: 0.882416\n"
     ]
    }
   ],
   "source": [
    "trn_lgb = lgb.Dataset(XX_trn, yy_trn)\n",
    "val_lgb = lgb.Dataset(XX_val, yy_val)\n",
    "\n",
    "lgb_params = {\n",
    "    'application': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 1,\n",
    "    'seed': 0,\n",
    "}\n",
    "train_round = 150\n",
    "\n",
    "bst = lgb.train(lgb_params, trn_lgb, train_round, valid_sets=[trn_lgb, val_lgb], early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**trian use all data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.train(lgb_params, lgb.Dataset(X_trn, y_trn), train_round)\n",
    "predictions = lgb_model.predict(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(predictions.clip(0,20), columns=[output_label_col])\n",
    "res_df[output_id_col] = tst_df[output_id_col].astype(int).values\n",
    "res_df.sort_values('ID')[[output_id_col, output_label_col]].to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
