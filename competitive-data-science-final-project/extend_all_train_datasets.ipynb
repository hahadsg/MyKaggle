{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练集扩展为(shop_id, item_id, date_block_num)的所有情况，没有销量的补0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from IPython.display import display\n",
    "\n",
    "from mydatools.plot import plot_grid_search_result\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trn_path = './data/input/train.csv'\n",
    "tst_path = './data/input/test.csv'\n",
    "id_col = 'ID'\n",
    "label_col = 'item_cnt_month'\n",
    "\n",
    "submission_path = './data/output/submission/extend_all_train_datasets.csv'\n",
    "output_id_col = id_col\n",
    "output_label_col = label_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_cate_df = pd.read_csv('./data/input/item_categories.csv')\n",
    "item_df = pd.read_csv('./data/input/items.csv')\n",
    "sales_df = pd.read_csv('./data/input/sales_train.csv')\n",
    "shop_df = pd.read_csv('./data/input/shops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>trn</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>trn</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trn</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>trn</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trn</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  date_block_num ds_type  item_cnt_month  item_id  shop_id\n",
       "0   0               1     trn            31.0       30        0\n",
       "1   0               1     trn            11.0       31        0\n",
       "2   0               0     trn             6.0       32        0\n",
       "3   0               1     trn            10.0       32        0\n",
       "4   0               0     trn             3.0       33        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df['revenue'] = sales_df['item_price'] * sales_df['item_cnt_day']\n",
    "trn_df = sales_df.groupby(['shop_id', 'item_id', 'date_block_num'])['item_cnt_day'].sum().reset_index()\n",
    "trn_df = trn_df.rename(columns={'item_cnt_day': 'item_cnt_month'})\n",
    "trn_df['ID'] = 0\n",
    "trn_df['ds_type'] = 'trn'\n",
    "\n",
    "tst_df = pd.read_csv(tst_path)\n",
    "tst_df['date_block_num'] = 34\n",
    "tst_df['item_cnt_month'] = 0\n",
    "tst_df['ds_type'] = 'tst'\n",
    "\n",
    "full_df = pd.concat([trn_df, tst_df])\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Valdation\n",
    "\n",
    "验证集策略：\n",
    "\n",
    "测试集是2015.11这个月的数据，需要预测所有店铺所有商品的销量\n",
    "\n",
    "那么验证集可以为2015.10这个月，所有店铺所有商品的数据，如果没有记录就补0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dbn in range(0, 34):\n",
    "    # 生成所有可能的(shop_id, item_id)\n",
    "    unique_shop_id = full_df[full_df['date_block_num'] == dbn]['shop_id'].copy().drop_duplicates()\n",
    "    unique_item_id = full_df[full_df['date_block_num'] == dbn]['item_id'].copy().drop_duplicates()\n",
    "    m_index = pd.MultiIndex.from_product([unique_shop_id, unique_item_id], names=['shop_id', 'item_id'])\n",
    "    val_df = pd.DataFrame([], index=m_index).reset_index()\n",
    "    val_df['ID'] = 0\n",
    "    val_df['date_block_num'] = dbn\n",
    "    # 为了区别开原始trn\n",
    "    val_df['ds_type'] = 'add_val'\n",
    "    # 去掉已经有的(shop_id, item_id)\n",
    "    origin_33_df = full_df[full_df['date_block_num'] == dbn][['item_id', 'shop_id', 'item_cnt_month']]\n",
    "    val_df = val_df.merge(origin_33_df, how='left', on=['item_id', 'shop_id'])\n",
    "    val_df = val_df[val_df.item_cnt_month.isnull()]\n",
    "    # 没有的记录 说明销售为0\n",
    "    val_df['item_cnt_month'] = 0\n",
    "\n",
    "    # 合并到full_df\n",
    "    full_df = pd.concat([full_df, val_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "def add_features(features):\n",
    "    if not isinstance(features, list):\n",
    "        features = [features]\n",
    "    global feature_columns\n",
    "    feature_columns.extend([f for f in features if f not in feature_columns])\n",
    "    \n",
    "def remove_features(features):\n",
    "    if not isinstance(features, list):\n",
    "        features = [features]\n",
    "    global feature_columns\n",
    "    feature_columns = [f for f in feature_columns if f not in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**shop_id, item_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add_features(['shop_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**datetime info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df['dt_year'] = full_df['date_block_num'] // 12 + 2013\n",
    "full_df['dt_month'] = full_df['date_block_num'] % 12 + 1\n",
    "add_features(['dt_year', 'dt_month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**item_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_name's words count\n",
    "item_df['item_name_words_count'] = item_df['item_name'].map(lambda x: len(x.split(' ')))\n",
    "\n",
    "# add to full_df\n",
    "full_df = full_df.merge(item_df, how='left', on='item_id')\n",
    "\n",
    "# add feautures\n",
    "add_features(['item_category_id', 'item_name_words_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mean encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_mean = full_df[full_df['date_block_num'] < 34]['item_cnt_month'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_aggragation_feature(df, groupby_cols, agg_col, fillna_value):\n",
    "    gb = df[df['ds_type'] == 'trn'].groupby(groupby_cols)[agg_col]\n",
    "    fname_fmt = '-'.join(groupby_cols+[agg_col]) + ':%s'\n",
    "    agg_df = pd.DataFrame({\n",
    "            fname_fmt%'mean': gb.mean(),\n",
    "#             fname_fmt%'median': gb.median(),\n",
    "#             fname_fmt%'max': gb.max(),\n",
    "#             fname_fmt%'min': gb.min(),\n",
    "        })\n",
    "    new_df = df.join(agg_df, on=groupby_cols).fillna(global_mean)\n",
    "    return new_df, agg_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupby_cols_list = [\n",
    "    ['shop_id', 'item_id'],\n",
    "    ['shop_id'],\n",
    "    ['item_id'],\n",
    "    ['date_block_num'],\n",
    "#     ['dt_year'],\n",
    "    ['dt_month'],\n",
    "    ['item_category_id'],\n",
    "]\n",
    "for groupby_cols in groupby_cols_list:\n",
    "    full_df, new_feats = get_aggragation_feature(full_df, groupby_cols, 'item_cnt_month', global_mean)\n",
    "    add_features(new_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lag features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_range = [1,2,3,6,12]\n",
    "shift_features = ['shop_id-item_id-item_cnt_month:mean', 'shop_id-item_cnt_month:mean', 'item_id-item_cnt_month:mean']\n",
    "\n",
    "for shift_month in shift_range:\n",
    "    tmp_df = full_df[['shop_id', 'item_id', 'date_block_num'] + shift_features].copy()\n",
    "    tmp_df['date_block_num'] = tmp_df['date_block_num'] + shift_month\n",
    "    for f in shift_features:\n",
    "        new_f = f + '_lag_' + str(shift_month)\n",
    "        tmp_df = tmp_df.rename(columns={f: new_f})\n",
    "        add_features(new_f)\n",
    "    full_df = full_df.merge(tmp_df, how='left', on=['shop_id', 'item_id', 'date_block_num']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove 2013\n",
    "full_df = full_df[full_df['date_block_num'] > 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**show all features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt_year',\n",
       " 'dt_month',\n",
       " 'item_category_id',\n",
       " 'item_name_words_count',\n",
       " 'shop_id-item_id-item_cnt_month:mean',\n",
       " 'shop_id-item_cnt_month:mean',\n",
       " 'item_id-item_cnt_month:mean',\n",
       " 'date_block_num-item_cnt_month:mean',\n",
       " 'dt_month-item_cnt_month:mean',\n",
       " 'item_category_id-item_cnt_month:mean',\n",
       " 'shop_id-item_id-item_cnt_month:mean_lag_1',\n",
       " 'shop_id-item_cnt_month:mean_lag_1',\n",
       " 'item_id-item_cnt_month:mean_lag_1',\n",
       " 'shop_id-item_id-item_cnt_month:mean_lag_2',\n",
       " 'shop_id-item_cnt_month:mean_lag_2',\n",
       " 'item_id-item_cnt_month:mean_lag_2',\n",
       " 'shop_id-item_id-item_cnt_month:mean_lag_3',\n",
       " 'shop_id-item_cnt_month:mean_lag_3',\n",
       " 'item_id-item_cnt_month:mean_lag_3',\n",
       " 'shop_id-item_id-item_cnt_month:mean_lag_6',\n",
       " 'shop_id-item_cnt_month:mean_lag_6',\n",
       " 'item_id-item_cnt_month:mean_lag_6',\n",
       " 'shop_id-item_id-item_cnt_month:mean_lag_12',\n",
       " 'shop_id-item_cnt_month:mean_lag_12',\n",
       " 'item_id-item_cnt_month:mean_lag_12']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level1 Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valdation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = full_df['date_block_num'].copy()\n",
    "\n",
    "trn_df = full_df[full_df['date_block_num'] <= 32]\n",
    "val_df = full_df[full_df['date_block_num'] == 33].copy()\n",
    "\n",
    "X_trn = trn_df[feature_columns]\n",
    "y_trn = trn_df[label_col]\n",
    "X_val = val_df[feature_columns]\n",
    "y_val = val_df[label_col]\n",
    "\n",
    "# scale\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_trn = scaler.fit_transform(X_trn)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(metrics.mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ElasticNet parameters tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.5, 'alpha': 0.001}\n",
      "5.176383252719356\n",
      "{'l1_ratio': 0.5, 'alpha': 0.01}\n",
      "5.173526624733808\n",
      "{'l1_ratio': 0.5, 'alpha': 0.1}\n",
      "5.17056142576454\n",
      "{'l1_ratio': 0.5, 'alpha': 1}\n",
      "5.181413162814315\n",
      "{'l1_ratio': 0.5, 'alpha': 10}\n",
      "5.342806335455328\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "#     'alpha': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'alpha': [1],\n",
    "#     'l1_ratio': [0, 0.25, 0.5, 0.75, 1],\n",
    "    'l1_ratio': [0.5],\n",
    "}\n",
    "\n",
    "best_score = 9999\n",
    "best_param = None\n",
    "for param in model_selection.ParameterGrid(param_grid):\n",
    "    print(param)\n",
    "    clf = ElasticNet(**param)\n",
    "    clf.fit(X_trn, y_trn)\n",
    "    s = rmse(y_val, clf.predict(X_val).clip(0,20))\n",
    "    if s < best_score:\n",
    "        best_score = s\n",
    "        best_param = param\n",
    "        val_df['pred'] = clf.predict(X_val).clip(0,20)\n",
    "    print(s)\n",
    "\n",
    "level1_en = ElasticNet(**best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM parameters tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'feature_fraction': 0.75,\n",
    "    'metric': 'rmse',\n",
    "    'nthread': 1, \n",
    "    'min_data_in_leaf': 2**7, \n",
    "    'bagging_fraction': 0.75, \n",
    "    'learning_rate': 0.03, \n",
    "    'objective': 'mse', \n",
    "    'bagging_seed': 2**7, \n",
    "    'num_leaves': 2**7,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get level2 train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_trn_level2 = dates_train[dates_train.isin([27, 28, 29, 30, 31, 32])]\n",
    "y_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_level2 = np.zeros([y_train_level2.shape[0], 2])\n",
    "\n",
    "for cur_block_num in [27, 28, 29, 30, 31, 32]:\n",
    "\n",
    "    print(cur_block_num)\n",
    "\n",
    "    X_trn_i = X_train[dates_train < cur_block_num]\n",
    "    y_trn_i = y_train[dates_train < cur_block_num]\n",
    "    X_tst_i = X_train[dates_train == cur_block_num]\n",
    "    \n",
    "    lr.fit(X_trn_i, y_trn_i)\n",
    "    X_train_level2[dates_train_level2 == cur_block_num, 0] = lr.predict(X_tst_i)\n",
    "    \n",
    "    lgb_model = lgb.train(lgb_params, lgb.Dataset(X_trn_i, label=y_trn_i), 100)\n",
    "    X_train_level2[dates_train_level2 == cur_block_num, 1] = lgb_model.predict(X_tst_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain(All data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_df = full_df[full_df['date_block_num'] <= 33]\n",
    "tst_df = full_df[full_df['date_block_num'] == 34]\n",
    "\n",
    "X_trn = trn_df[feature_columns]\n",
    "y_trn = trn_df[label_col]\n",
    "X_tst = tst_df[feature_columns]\n",
    "\n",
    "# scale\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_trn = scaler.fit_transform(X_trn)\n",
    "X_tst = scaler.transform(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ElasticNet(**best_param)\n",
    "model.fit(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(model.predict(X_tst).clip(0,20), columns=[output_label_col])\n",
    "res_df[output_id_col] = tst_df[output_id_col].astype(int).values\n",
    "res_df[[output_id_col, output_label_col]].to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
