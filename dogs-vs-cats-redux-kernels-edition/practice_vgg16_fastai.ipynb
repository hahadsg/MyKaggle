{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5103 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:1E.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from mydatools import img_plot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = 'data/input/all/'\n",
    "path = 'data/input/sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, gen=ImageDataGenerator(), shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224)):\n",
    "    return gen.flow_from_directory(dirname, target_size=target_size,\n",
    "            class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)\n",
    "\n",
    "def get_data(path, target_size=(224,224)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, target_size=target_size)\n",
    "    X = np.concatenate([batches.next()[0] for i in range(batches.samples)])\n",
    "    y = np.concatenate([batches.next()[1] for i in range(batches.samples)])\n",
    "    return X, y, batches\n",
    "\n",
    "def get_class(a_onehot):\n",
    "    return a_onehot.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, batches, val_batches, nb_epoch=1):\n",
    "    model.fit_generator(batches, samples_per_epoch=batches.samples, nb_epoch=nb_epoch, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "tra_batches = get_batches(path+'train', shuffle=True, batch_size=64)\n",
    "val_batches = get_batches(path+'val', shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vgg16\n",
    "from vgg16 import Vgg16\n",
    "model = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.finetune(tra_batches)\n",
    "\n",
    "#Not sure if we set this for all fits\n",
    "model.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "28/28 [==============================] - 39s - loss: 0.7233 - acc: 0.9202 - val_loss: 0.2740 - val_acc: 0.9740\n",
      "Epoch 2/3\n",
      "28/28 [==============================] - 77s - loss: 0.2236 - acc: 0.9827 - val_loss: 0.3508 - val_acc: 0.9706\n",
      "Epoch 3/3\n",
      "28/28 [==============================] - 81s - loss: 0.2393 - acc: 0.9788 - val_loss: 0.2927 - val_acc: 0.9706\n"
     ]
    }
   ],
   "source": [
    "model.fit(tra_batches, val_batches, nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
